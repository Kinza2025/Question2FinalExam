{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xT9n3M42B6v"
   },
   "source": [
    "##Question 2 Final Exam:\n",
    "\n",
    "Using Agent Pro, build a real, functioning AI Agent leveraging a Multi-Agent Architecture to solve a real world problem.\n",
    "\n",
    "Answer:\n",
    "\"Tool-Based Multi-Agent Q&A Assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4bMlaSg4Vti"
   },
   "source": [
    "A working chatbot system with:\n",
    "\n",
    "ðŸ”¹ CalculatorBot â€“ for math expressions\n",
    "\n",
    "ðŸ”¹ ARES TOOL â€“ for Internet Search\n",
    "\n",
    "ðŸ”¹ DUCK DUCK GO  â€“ for For Youtube Video Links\n",
    "\n",
    "ðŸ”¹ WikiBot â€“ for general knowledge searching on Wikipedia\n",
    "\n",
    "ðŸ”¹ MistralBot â€“ an LLM answering complex questions\n",
    "\n",
    "ðŸ”¹ Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5912,
     "status": "ok",
     "timestamp": 1749130567905,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "rgASt3qM2TFw",
    "outputId": "887e32f9-7a82-4649-8fa4-1d9b50655a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
      "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the Hugging Face 'transformers' library for working with pre-trained language models\n",
    "# Install 'accelerate' to simplify model training and hardware utilization (e.g., GPU/TPU)\n",
    "# Install 'wikipedia' to enable searching and fetching content from Wikipedia programmatically\n",
    "!pip install transformers accelerate wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6125,
     "status": "ok",
     "timestamp": 1749130597845,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "kIhQBnPzElFk",
    "outputId": "a8184e2b-00f4-4c57-af6f-6a67f324e147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Install the 'requests' library, which is used to send HTTP/1.1 requests easily in Python\n",
    "# Useful for making API calls, downloading web content, and interacting with web services\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUzVwr_VMmjE"
   },
   "source": [
    "Youtube Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3630,
     "status": "ok",
     "timestamp": 1749130601481,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "NcXXn6LjNUf6",
    "outputId": "584fc619-64a3-4e2d-8d8d-a2ae91953615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.0.2)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
      "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.15.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the 'duckduckgo-search' library, which provides a simple interface\n",
    "# to perform searches using the DuckDuckGo search engine from Python\n",
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749130606416,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "qnR23QLxMlm8"
   },
   "outputs": [],
   "source": [
    "# Import DDGS (DuckDuckGo Search) class to perform searches including videos\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Import utilities to parse URLs and query strings\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Define a custom class to perform YouTube searches using DuckDuckGo\n",
    "class YouTubeSearchTool:\n",
    "\n",
    "    # Constructor method: initialize the DDGS search instance\n",
    "    def __init__(self):\n",
    "        self.ddgs = DDGS()\n",
    "\n",
    "    # Helper method to extract a YouTube video ID from a given URL\n",
    "    def extract_video_id(self, url):\n",
    "        parsed_url = urlparse(url)  # Parse the input URL\n",
    "        # Handle standard YouTube watch links\n",
    "        if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
    "            if parsed_url.path == '/watch':\n",
    "                # Extract video ID from the query string parameter 'v'\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "            elif parsed_url.path.startswith('/shorts/'):\n",
    "                # Extract video ID from YouTube Shorts URLs\n",
    "                return parsed_url.path.split('/')[2]\n",
    "        # Handle shortened YouTube links (youtu.be)\n",
    "        elif parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        # If the URL is not recognized as a YouTube link\n",
    "        return None\n",
    "\n",
    "    # Method to perform a YouTube video search using DuckDuckGo\n",
    "    def search_videos(self, query, max_results=3):\n",
    "        try:\n",
    "            # Perform the video search with custom filters\n",
    "            results = self.ddgs.videos(\n",
    "                keywords=query,       # Search query\n",
    "                region=\"wt-wt\",       # Region (wt-wt is worldwide)\n",
    "                safesearch=\"off\",     # Disable safe search filtering\n",
    "                timelimit=\"w\",        # Limit to videos from the past week\n",
    "                resolution=\"high\",    # Prefer high-resolution videos\n",
    "                duration=\"medium\",    # Prefer medium-duration videos\n",
    "                max_results=max_results * 2  # Fetch more than needed for filtering\n",
    "            )\n",
    "            # Sort results by view count in descending order\n",
    "            results = sorted(results, key=lambda x: -(x.get('statistics', {}).get('viewCount', 0)))\n",
    "\n",
    "            videos = []  # List to store filtered video info\n",
    "            for result in results[:max_results]:  # Limit to the top N results\n",
    "                video_url = result.get('content')  # Extract video URL\n",
    "                video_id = self.extract_video_id(video_url)  # Extract video ID\n",
    "                if video_id:\n",
    "                    # Build a structured video info dictionary\n",
    "                    videos.append({\n",
    "                        'title': result['title'],  # Video title\n",
    "                        'video_id': video_id,      # YouTube video ID\n",
    "                        'description': result.get('description', ''),  # Video description\n",
    "                        'link': video_url,         # Full video URL\n",
    "                        'view_count': result.get('statistics', {}).get('viewCount', 'N/A')  # View count\n",
    "                    })\n",
    "            # Return the list of videos, or a message if none were found\n",
    "            return videos or \"No relevant YouTube videos found.\"\n",
    "\n",
    "        # Handle and return any errors that occur during search\n",
    "        except Exception as e:\n",
    "            return f\"Error during YouTube search: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yokrFPYs5JA5"
   },
   "source": [
    "Loading Mistralai Model as Base Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1749130713222,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "rAJVisCS3_sf"
   },
   "outputs": [],
   "source": [
    "# Import the Hugging Face Transformers tokenizer and model for causal language modeling\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Import PyTorch for tensor operations and device management\n",
    "import torch\n",
    "\n",
    "# Import regular expressions module for parsing/calculations\n",
    "import re\n",
    "\n",
    "# Import Wikipedia library for fetching summaries from Wikipedia\n",
    "import wikipedia\n",
    "\n",
    "# Import OS library (currently unused in the code but may be useful later)\n",
    "import os\n",
    "\n",
    "\n",
    "# Define a class to interact with the Mistral-7B-Instruct language model\n",
    "class MistralBot:\n",
    "    # Constructor: load the tokenizer and model from Hugging Face\n",
    "    def __init__(self, model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
    "        print(\"Loading Mistral-7B-Instruct model...\")\n",
    "        # Load tokenizer for the specified model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Load the language model with float16 precision and automatic device placement (e.g., GPU/CPU)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    # Generate text from the model using the given prompt\n",
    "    def generate(self, prompt, max_tokens=150):\n",
    "        # Tokenize the prompt and move it to the same device as the model\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        # Generate output using the model with sampling\n",
    "        outputs = self.model.generate(**inputs, max_new_tokens=max_tokens, do_sample=True)\n",
    "        # Decode the generated tokens to text\n",
    "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Extract only the portion after \"Final Answer:\" (if exists)\n",
    "        return text.split(\"Final Answer:\")[-1].strip()\n",
    "\n",
    "\n",
    "# Define an agent that uses tools and an LLM to answer questions\n",
    "class ToolBasedAgent:\n",
    "    # Constructor: accept an instance of MistralBot or similar model\n",
    "    def __init__(self, llm_agent):\n",
    "        self.llm_model = llm_agent  # Assign the language model\n",
    "\n",
    "    # Calculator tool: extract and evaluate basic math expressions from a string\n",
    "    def calculator(self, question):\n",
    "        # Use regex to find a simple arithmetic expression (e.g., \"12 + 5\")\n",
    "        match = re.findall(r\"[-+]?\\d+\\.?\\d*\\s*[\\+\\-\\*/]\\s*[-+]?\\d+\\.?\\d*\", question)\n",
    "        if match:\n",
    "            try:\n",
    "                # Evaluate the first matched expression safely\n",
    "                return str(eval(match[0]))\n",
    "            except:\n",
    "                return \"Calculation error.\"\n",
    "        return None\n",
    "\n",
    "    # Wikipedia tool: fetch a short summary for a given topic\n",
    "    def wiki(self, question):\n",
    "        try:\n",
    "            # Return the first two sentences from Wikipedia summary\n",
    "            return wikipedia.summary(question, sentences=2)\n",
    "        except:\n",
    "            return None  # Return None if the topic isn't found or any error occurs\n",
    "\n",
    "    # Run the language model with a prompt\n",
    "    def run_llm(self, prompt):\n",
    "        return self.llm_model.generate(prompt)\n",
    "\n",
    "    # Web search tool using Ares API\n",
    "    def web_search(self, query):\n",
    "        try:\n",
    "            url = \"https://api.aresapi.com/search\"  # Ares API endpoint\n",
    "            headers = {\n",
    "                \"X-API-Key\": self.ares_api_key  # API key for authentication\n",
    "            }\n",
    "            params = {\n",
    "                \"q\": query,       # Query string\n",
    "                \"num\": 3          # Limit results to top 3\n",
    "            }\n",
    "            # Make GET request to Ares API\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            # Extract result list from JSON response\n",
    "            results = response.json().get(\"results\", [])\n",
    "            if not results:\n",
    "                return \"No web results found.\"\n",
    "            # Format results as bullet points with title and URL\n",
    "            return \"\\n\".join([f\"- {r['title']}: {r['url']}\" for r in results])\n",
    "        except Exception as e:\n",
    "            # Handle any API or network errors\n",
    "            return f\"Ares error: {str(e)}\"\n",
    "\n",
    "    # YouTube search tool\n",
    "    def youtube_search(self, query):\n",
    "        return self.youtube_tool.search_videos(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TqwWt3O7AmZ"
   },
   "source": [
    "React Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749130753820,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "B4OmnQQe5mXh"
   },
   "outputs": [],
   "source": [
    "# Define the ReAct reasoning loop function\n",
    "# agent: an instance of ToolBasedAgent with tools like calculator, wiki, and LLM\n",
    "# user_question: the original question asked by the user\n",
    "# max_steps: how many reasoning steps to allow before forcing a final answer\n",
    "def react_loop(agent, user_question, max_steps=5):\n",
    "\n",
    "    # Description of tools available to the agent, included in the system prompt\n",
    "    tools_description = \"\"\"\n",
    "Calculator: useful for solving math problems and equations.\n",
    "Wiki: useful for retrieving short summaries from Wikipedia.\n",
    "\"\"\"\n",
    "\n",
    "    # The list of valid tool/action names, including the final answer\n",
    "    tool_names = \"Calculator, Wiki, Answer\"\n",
    "\n",
    "    # System prompt that defines the ReAct-style instruction format for the agent\n",
    "    system_prompt = f\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools_description}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\"\"\"\n",
    "\n",
    "    # Initialize the conversation history with the user question\n",
    "    history = f\"Question: {user_question}\\n\"\n",
    "\n",
    "    # Begin the reasoning loop for up to `max_steps` iterations\n",
    "    for _ in range(max_steps):\n",
    "        # Construct the prompt for the LLM by appending current history to the system prompt\n",
    "        prompt = system_prompt + history\n",
    "        # Run the LLM on the prompt to get the next reasoning step\n",
    "        response = agent.run_llm(prompt)\n",
    "\n",
    "        # Convert response to lowercase for easier matching\n",
    "        lower_resp = response.lower()\n",
    "\n",
    "        # Check which tool was chosen by the agent\n",
    "        if \"action: calculator\" in lower_resp:\n",
    "            action = \"Calculator\"\n",
    "            action_input = user_question  # In this simplified version, we reuse the original question\n",
    "            observation = agent.calculator(action_input)  # Call the calculator tool\n",
    "\n",
    "        elif \"action: wiki\" in lower_resp:\n",
    "            action = \"Wiki\"\n",
    "            action_input = user_question\n",
    "            observation = agent.wiki(action_input)  # Call the Wikipedia tool\n",
    "\n",
    "        elif \"final answer\" in lower_resp:\n",
    "            # If the model directly gives the final answer, return it\n",
    "            return response.strip()\n",
    "\n",
    "        else:\n",
    "            # If the model doesnâ€™t follow the expected format, stop and return what it gave\n",
    "            return f\"Final Answer: {response.strip()}\"\n",
    "\n",
    "        # Update the reasoning history with the agent's response and tool observation\n",
    "        history += f\"{response.strip()}\\nObservation: {observation}\\n\"\n",
    "\n",
    "    # If max_steps are exhausted and no final answer was given,\n",
    "    # explicitly ask the model to produce the final answer\n",
    "    final_prompt = system_prompt + history + \"Thought: I now know the final answer\\nFinal Answer:\"\n",
    "    final_response = agent.run_llm(final_prompt)\n",
    "\n",
    "    return final_response.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ity0NK-85fGJ"
   },
   "source": [
    "Run the Multi Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505,
     "referenced_widgets": [
      "5d9573b40ab047ae805478bc74658ff9",
      "6d3446d5e6d841e7a04e1185838dcf91",
      "badd25e62ebe47489e4b03fb5ca7ab49",
      "75bc5cc4ec6f4717b27dd07e76ab85b7",
      "bec9566fcc554101828c9d76ad4eb67f",
      "94635cbc613e40f4800d5dfd4d4a167b",
      "7668fb447d5f44b99799c8a4c7cab04f",
      "30d51a5f7127443d9054766a9268d7e1",
      "7cebc33a6d1f465bbe297d6465832a7f",
      "b40ff22e1fa04c42ac83d8c2c58faf65",
      "447939814db14124855c9ea8cb358800",
      "965c9da43fd645bea2da44fa4420daeb",
      "196bd97cfcd74fff99f0f1d17428bd6a",
      "1ae42247cc5c415fa59ceb313c13d60d",
      "66cc65713c0f4cd3a9441e44c634e0ac",
      "b1ca32cc84814bfc802961a32596f5cd",
      "ea528dea93fa4270b4d0ccd726bf4758",
      "ac9eeeeb271c487aa6c1ac24889e0ec7",
      "1353bda669d74f768224e382bb06c8d1",
      "7fdf8e315d89407ab5fd1980a34ef19d",
      "488649edd29f421f88511a93be50103b",
      "1318e3d2158441b2b6728a74bd0c02db",
      "94b1dde365de486a9f0994ca414f9faa",
      "61ec7208d406486594df7ff04bf7a844",
      "5fcc7088d9ee4451ad743811e022b8f9",
      "68e15413e8a2453ca3d4e6d238a655e4",
      "15af0f9d8a7741388f7f7d9ba6da0575",
      "91c117e46b5c49f3b19aec31fb6a9aec",
      "04bff0ce33794aeabd1bf44715a39d1b",
      "1ccb8ab70b134c469d829b7c5793fe13",
      "5f9384f37b2447ed8f8197d039d2b547",
      "028be8d52120443cae378f6c82029046",
      "6b92c03f07894a9daa9eea1cd236cc5c",
      "96b366ae6f494acd8bf05bdfd708968d",
      "9aa45d8b3b0649f89abd134c523b3043",
      "7ae732cee8d54c0a82ced03d77e282bf",
      "ea48548d91744362b149db043d3ad662",
      "b7d87f93dd014d2b8b68fc2b9b8ea1f6",
      "d665817033fa4d178e3a505a72493d0c",
      "7f586081070a4e0d8dc996c0f8b13576",
      "a3a71e03a6f34e4ebaaca94dd509e042",
      "953cab7bad9d4c41bd0fe29561277a61",
      "efcc033ba2064f5da6cb5fe3f6f78f2d",
      "30dac193ac0e40238544a85561649aa8",
      "c5e7a0258d2b4d84bc7708066e198683",
      "612ce32a7c6c45b4af749e5a33f58b6d",
      "16092044f27c489f896f827d4fcb4de0",
      "1e0ae15c24f445aea8dd941d461ab672",
      "7a7bf77cfca34ae99ee9ceef69b7b2ef",
      "cdb13037eba7405ca007ce5e688d551e",
      "3786395371b543d4b7e48b62062aa932",
      "3af05e6a9615471dac887009a0e960ec",
      "4066d3b1cad94d9c86de78378deb7352",
      "25acd3db50654bc69becce9f6b46135d",
      "76e2cd6911184a89be32d49576ebd4e5",
      "64d8e10e4ecb42a3a98d0724c8ef8c87",
      "56d5893176fa4e689dbd2951ff77abdb",
      "dd165638ff8848d3a343dd3588da4d1f",
      "6b05cabd5e6849f69ed869315b47bf9f",
      "92442ee7f7934db8b8c3a43790ff7be0",
      "2de09c4d0f03461ba4c3d4c84dfeaf4a",
      "857dc0f385ca425a85a42ea5df791324",
      "0be3cb6ffc3644d2aebb0fb38b989dfc",
      "b96e2daacbbf442ea749d7124b68a1ee",
      "79350f1a433b4a52a898423e74576ecd",
      "6beaa4b485354428a8ae1951f8d504c7",
      "3220ed1ee8ed4486b07e1b5c7923cfbc",
      "361a08cd3b9e4d57b3d39ceb92089703",
      "6f165cb0cb024258a6acac3a31d7c2c8",
      "3ea6b5206ce14c52ac28a1021987118b",
      "6c0e27bd7bd7435194eaac7dad63ce54",
      "af7b4ece34464bc78542329202b8e675",
      "4692ec4789fd4f77a169041d7a48ecde",
      "77aa60b002bf4d9da056836588cff04b",
      "a986478273934e078fa74a7438787919",
      "b93a951d3a764eb78b86827284c76216",
      "74e63f2bbc9348bba9e5c2ca218cb7d8",
      "7ba08a04962843d280060ca896457624",
      "343c8495406c48f19d109c05aae5bda7",
      "086f76bafc35491781217e0f6adae685",
      "4b718b7ae6b54a8cb0cdbfd4871ea4dc",
      "b80717660beb447cb1153d643aa7e86e",
      "d34e9e4b620d433784f57b2a5717fa7b",
      "f290360654c04bb89a55d9f8a6bc0a2b",
      "f95c43b9e6cf4d13abc19bc1c5ca42f7",
      "b00e08ab268f4dfcb8d697c02252a7e7",
      "7275f6ebb0a04c4f867561da7dd04b2f",
      "30f098e201ed4b4d8a630a0d8c8466a0",
      "43e0243ddfe746cc8b2df9b80ccaa1ad",
      "fa8cab400652439ca47b22666eaab6ad",
      "c8fb1cb7aaac45be9e448ddf494478ca",
      "0b0f837b0b3b4c8585ff4a2c68a1dcd8",
      "4b87747fb2504e99932a77638882c1f2",
      "e8c93026df4a433b80b0f55956fe68df",
      "590ecc278e3240dbbb45aeeddc1ea990",
      "0f106ae6882145ca9ee7f81ac13a5bf4",
      "7f39bccc5c604cb0a6e51b97c382ab7e",
      "5ee982b6b3ee45bebc810b300b4a02ea",
      "9f5cd29b18834443bd23c68eb3a06191",
      "6224ba71cb5748acb5ee9e8b5b9e9cbf",
      "d59d9e0ef0de4a55932eacfad1fc4060",
      "496761a8709b45ba9e07690dd24dfaa0",
      "6fe1de1b086b439ba3436d08049bd8f5",
      "6108dac5730d41f5a681cf57469c75e9",
      "3ddc43ac09e444879bc0dfa1de40f449",
      "40a41d58f88441e6a042abd89a7660de",
      "7deaef8800204b45b6b08fb14e788b8d",
      "f79847aca23f4b888e5fc9c430b21e22",
      "a98164dab7b44458a41a1178ee10ab65",
      "a21cacb2dd7546e28b06cf2918e2486f",
      "42d0ca8a6b8c4cc0a1dc946358473662",
      "34f1397c2539457280cc81467d8f8add",
      "d8d608e190f54624b33a808c9adb427e",
      "8be97b21730a410d80f88e6cb48f4f07",
      "3ae03743a79548bc9c2165e6eb455c5f",
      "a445ba8419c341b484cb2bb363359d31",
      "9cba555639dd4d21ab09cab8da1633f7",
      "7455f1240aef4b239dae6c0f465504fd",
      "c06226066aba42f1bb09ee950ad1d3dd",
      "ae93608fd0e94ce99d65820f069a6bb7",
      "b7a7a2bf392146e19d4270788f835fa4",
      "3e65c4b180b8439bb1c9bb0e96ec435a",
      "59f4d43b0b40483c851f7e0f68f379df",
      "146ef5d7a50d4d289a30928ed4ed4075",
      "191cc565f08d483dac209b15bc6c61ad",
      "bcd986aa702141dea4376bc4307680e6",
      "8f7a1b46b3bd4b569bea44b6c0a7caf7",
      "e8b819aa38b347598871b450ced7bea3",
      "c371b7e7c05d4376ac49cd63cc7b0bd9",
      "380158584b774588acf7df9b3a4bb999",
      "e879cbf7621a4e9b9214c9554944edf1",
      "fdf355fe35604c1aa43faa089d845e90"
     ]
    },
    "executionInfo": {
     "elapsed": 339450,
     "status": "ok",
     "timestamp": 1749129798625,
     "user": {
      "displayName": "Kinza Shameen",
      "userId": "16533180055193273591"
     },
     "user_tz": -300
    },
    "id": "GJek3OtL5447",
    "outputId": "be5abafe-35f3-4f03-b5ae-f52dff154cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mistral-7B-Instruct model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9573b40ab047ae805478bc74658ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965c9da43fd645bea2da44fa4420daeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1dde365de486a9f0994ca414f9faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b366ae6f494acd8bf05bdfd708968d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e7a0258d2b4d84bc7708066e198683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d8e10e4ecb42a3a98d0724c8ef8c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3220ed1ee8ed4486b07e1b5c7923cfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba08a04962843d280060ca896457624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e0243ddfe746cc8b2df9b80ccaa1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6224ba71cb5748acb5ee9e8b5b9e9cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d0ca8a6b8c4cc0a1dc946358473662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e65c4b180b8439bb1c9bb0e96ec435a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "FINAL ANSWER:\n",
      " Final Answer: Newton's second law of motion states that the net force acting on an object is equal to the mass of that object multiplied by its acceleration (F = ma).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the MistralBot language model (loads the Mistral-7B-Instruct model)\n",
    "mistral = MistralBot()\n",
    "\n",
    "# Create an instance of ToolBasedAgent and pass the Mistral model to it\n",
    "# This agent can now use LLM responses along with tools like calculator and Wikipedia\n",
    "agent = ToolBasedAgent(mistral)\n",
    "\n",
    "# Define the user's question to be answered using the reasoning loop\n",
    "user_question = \"What is Newton's second law of motion?\"\n",
    "\n",
    "# Run the ReAct-style reasoning loop with the agent to get a final response\n",
    "final_response = react_loop(agent, user_question)\n",
    "\n",
    "# Print the final answer returned by the reasoning loop\n",
    "print(\"FINAL ANSWER:\\n\", final_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KG9R79-8SJKE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
